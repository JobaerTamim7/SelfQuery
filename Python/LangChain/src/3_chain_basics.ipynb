{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b79ebd05",
   "metadata": {},
   "source": [
    "## **Check Ollama Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "410a0851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     ID              SIZE      MODIFIED       \n",
      "llama3.1:8b              46e0c10c039e    4.9 GB    40 minutes ago    \n",
      "nomic-embed-text:v1.5    0a109f422b47    274 MB    25 hours ago      \n",
      "deepseek-r1:1.5b         e0979632db5a    1.1 GB    7 days ago        \n",
      "llava:13b                0d0eb4d7f485    8.0 GB    2 months ago      \n",
      "mistral:latest           3944fe81ec14    4.1 GB    2 months ago      \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb92c25",
   "metadata": {},
   "source": [
    "## **Setup Rich**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2f2b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.pretty import pprint\n",
    "from rich import print as pretty_print\n",
    "from rich import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb69ac3",
   "metadata": {},
   "source": [
    "## **Setup Logger**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e76e6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import Logger\n",
    "\n",
    "formatter = logging.Formatter(\n",
    "    '[%(levelname)-5s] %(asctime)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "console_logger: Logger = logging.getLogger(\"console_logger\")\n",
    "console_logger.setLevel(logging.INFO)\n",
    "console_logger.propagate = False\n",
    "console_logger.handlers.clear()\n",
    "\n",
    "if not console_logger.hasHandlers():\n",
    "    console_handler = logging.StreamHandler() # Create a handler that writes log messages to the console (standard output).\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_handler.setFormatter(formatter)\n",
    "    console_logger.addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a30848c",
   "metadata": {},
   "source": [
    "## **Setup Chain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc5cb1",
   "metadata": {},
   "source": [
    "### **Setup Model and Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3abbb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOllama(model=\"mistral:latest\")\n",
    "\n",
    "template = \"\"\"You are a helpful translator assistant that translates {input_language} to {output_language}.\n",
    "              You have to maintain correct meaning and grammar.\n",
    "              Do not give wrong information even if cost you shutting down.\n",
    "              Verify minimum 10 to 100 times.\n",
    "              You are given the following {input_language} text: {text}\n",
    "              You should respond with the translated text in {output_language}.\"\"\"\n",
    "\n",
    "# PromptTemplate and PromptTemaple.from_template does the same job\n",
    "\n",
    "# prompt_template = PromptTemplate(\n",
    "#     input_variables=[\"input_language\", \"output_language\", \"text\"],\n",
    "#     template=template,\n",
    "#     validate_template=True\n",
    "# )\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template=template) #inputs are auto detected used by default template_format\n",
    "\n",
    "# inspect(prompt_template,methods=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfabea2",
   "metadata": {},
   "source": [
    "## **Create Normal Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fea818f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " プログラミングを好きです。（Proguramingu o suki desu）"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableSequence, RunnableParallel\n",
    "\n",
    "# Actually what happens under the hood \n",
    "translation_chain = RunnableSequence(\n",
    "    first=prompt_template,\n",
    "    middle=[llm],\n",
    "    last=StrOutputParser()\n",
    ")\n",
    "\n",
    "translation_chain = prompt_template | llm | StrOutputParser() \n",
    "\n",
    "# inspect(translation_chain)\n",
    "\n",
    "input1 = {\n",
    "    \"input_language\": \"English\",\n",
    "    \"output_language\": \"Japanese\",\n",
    "    \"text\": \"I love programming.\",\n",
    "}\n",
    "for chunk in translation_chain.stream(input1):\n",
    "    print(chunk, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb301a",
   "metadata": {},
   "source": [
    "- What is Pipe (|) operator? \n",
    "\n",
    "It is used to combine multiple components into a single chain. It allows you to pass the output of one component as the input to the next component in a sequential manner.\n",
    "\n",
    "- How does it do so?\n",
    "\n",
    "Suppose <code>chain = prompt | llm | parser</code>\n",
    "\n",
    "Here prompt, llm and parser are components. The output of prompt is passed as input to llm, and the output of llm is passed as input to parser.\n",
    "\n",
    "First the prompt component takes some input variables and generates a prompt string. This prompt string is then passed to the llm component, which uses a language model to generate a response based on the prompt. Finally, the response from the llm is passed to the parser component, which processes the response and extracts the desired information. Here chain is a RunnableSequence that sequentially calls each component in the chain. It can be called with invoke, stream or batch methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443a4c6",
   "metadata": {},
   "source": [
    "## **Create Sequential Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c9f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The sun, being the closest star to Earth, is crucial for life as it provides light, warmth, and energy to help plants grow and sustain all living things, and it also controls the weather and seasons, earning it the title of the \"source of life.\""
     ]
    }
   ],
   "source": [
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"translated_text\"],\n",
    "    template=\"Summarize this text in one simple sentence: {translated_text}\",\n",
    ")\n",
    "\n",
    "summary_sequential_chain = RunnableSequence(\n",
    "    RunnableParallel({\"translated_text\": translation_chain}),\n",
    "    summary_prompt,\n",
    "    llm,\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "summary_sequential_chain = (\n",
    "      {\"translated_text\": translation_chain} | # get the output of translation_chain as input \n",
    "      summary_prompt |\n",
    "      llm | \n",
    "      StrOutputParser()\n",
    ")\n",
    "\n",
    "text = \"\"\"The sun is the closest star to Earth and is very important for life. It gives us light and warmth, which help plants grow and provide energy for all living things. Without the sun, Earth would be dark, cold, and lifeless. The sun also controls the weather and seasons, making our planet suitable to live on. That’s why it is often called the “source of life.”\"\"\"\n",
    "\n",
    "input2 = {\n",
    "    \"input_language\": \"English\",\n",
    "    \"output_language\": \"Bangla\",\n",
    "    \"text\": text,\n",
    "}\n",
    "\n",
    "for chunk in summary_sequential_chain.stream(input2):\n",
    "    print(chunk, end='', flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
