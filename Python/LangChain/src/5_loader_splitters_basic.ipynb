{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1e1459",
   "metadata": {},
   "source": [
    "## **Setup Console**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bacde24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich import print as pretty_print\n",
    "from rich.pretty import pprint\n",
    "from rich import inspect\n",
    "\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc6d10",
   "metadata": {},
   "source": [
    "## **Setup PDF Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79ea1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Length of documents: </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">11</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;37mLength of documents: \u001b[0m\u001b[1;37m11\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'producer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PyPDF2'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'creator'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PyPDF'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'creationdate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'subject'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Neural Information Processing Systems http://nips.cc/'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'publisher'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Curran Associates, Inc.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en-US'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'created'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2017'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eventtype'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Poster'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'description-abstract'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Attention is All you Need'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2017'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'moddate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2018-02-12T21:22:10-08:00'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'published'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2017'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Conference Proceedings'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'firstpage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5998'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'book'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Advances in Neural Information Processing Systems 30'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'editors'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'lastpage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'6008'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../assets/NIPS-2017-attention-is-all-you-need-Paper.pdf'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser ∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'producer'\u001b[0m: \u001b[32m'PyPDF2'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'creator'\u001b[0m: \u001b[32m'PyPDF'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'creationdate'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'subject'\u001b[0m: \u001b[32m'Neural Information Processing Systems http://nips.cc/'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'publisher'\u001b[0m: \u001b[32m'Curran Associates, Inc.'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'language'\u001b[0m: \u001b[32m'en-US'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'created'\u001b[0m: \u001b[32m'2017'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'eventtype'\u001b[0m: \u001b[32m'Poster'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'description-abstract'\u001b[0m: \u001b[32m'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Attention is All you Need'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'date'\u001b[0m: \u001b[32m'2017'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'moddate'\u001b[0m: \u001b[32m'2018-02-12T21:22:10-08:00'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'published'\u001b[0m: \u001b[32m'2017'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'Conference Proceedings'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'firstpage'\u001b[0m: \u001b[32m'5998'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'book'\u001b[0m: \u001b[32m'Advances in Neural Information Processing Systems 30'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'description'\u001b[0m: \u001b[32m'Paper accepted and presented at the Neural Information Processing Systems Conference \u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttp://nips.cc/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'editors'\u001b[0m: \u001b[32m'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'author'\u001b[0m: \u001b[32m'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'lastpage'\u001b[0m: \u001b[32m'6008'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'../assets/NIPS-2017-attention-is-all-you-need-Paper.pdf'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'total_pages'\u001b[0m: \u001b[1;36m11\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'page'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'page_label'\u001b[0m: \u001b[32m'1'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mpage_content\u001b[0m=\u001b[32m'Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser ∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory \u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m and gated recurrent \u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation \u001b[0m\u001b[32m[\u001b[0m\u001b[32m 29, 2, 5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures \u001b[0m\u001b[32m[\u001b[0m\u001b[32m31, 21, 13\u001b[0m\u001b[32m]\u001b[0m\u001b[32m.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems \u001b[0m\u001b[32m(\u001b[0m\u001b[32mNIPS 2017\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, Long Beach, CA, USA.'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "loader: PyPDFLoader = PyPDFLoader(\"../assets/NIPS-2017-attention-is-all-you-need-Paper.pdf\")\n",
    "documents: list[Document] = loader.load()\n",
    "\n",
    "pretty_print(f\"[bold white]Length of documents: {len(documents)}[/]\")\n",
    "pprint(documents[0])\n",
    "# inspect(documents,methods=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c84844",
   "metadata": {},
   "source": [
    "## **Setup TextSplitter**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87dab4a",
   "metadata": {},
   "source": [
    "### **Normal One**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582467fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">Length of split documents: </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">76</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;37mLength of split documents: \u001b[0m\u001b[1;37m76\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'langchain_core.documents.base.Document'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&gt;</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Class for storing a piece of text and associated metadata.</span>                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────╮</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'producer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PyPDF2'</span>,                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'creator'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PyPDF'</span>,                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'creationdate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'subject'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Neural Information Processing Systems http://nips.cc/'</span>,                                 <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'publisher'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Curran Associates, Inc.'</span>,                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en-US'</span>,                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'created'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2017'</span>,                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eventtype'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Poster'</span>,                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'description-abstract'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The dominant sequence transduction models are based on compl'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">798</span>,         <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Attention is All you Need'</span>,                                                               <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">...</span> +<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'illia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence tr'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">437</span>                       <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">)</span>                                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                    <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">id</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>         <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">lc_attributes</span> = <span style=\"font-weight: bold\">{}</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>            <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">lc_secrets</span> = <span style=\"font-weight: bold\">{}</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>              <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">metadata</span> = <span style=\"font-weight: bold\">{</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'producer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PyPDF2'</span>,                                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'creator'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PyPDF'</span>,                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'creationdate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'subject'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Neural Information Processing Systems http://nips.cc/'</span>,                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'publisher'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Curran Associates, Inc.'</span>,                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en-US'</span>,                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'created'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2017'</span>,                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'eventtype'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Poster'</span>,                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'description-abstract'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The dominant sequence transduction models are based on </span>    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">complex recurrent orconvolutional neural networks in an encoder and decoder </span>            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">configuration. The best performing such models also connect the encoder and decoder </span>    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">through an attentionm echanisms.  We propose a novel, simple network architecture based</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">solely onan attention mechanism, dispensing with recurrence and convolutions </span>           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">entirely.Experiments on two machine translation tasks show these models to be </span>          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">superiorin quality while being more parallelizable and requiring significantly less </span>    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU </span>         <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">onEnglish-to-German translation, improving over the existing best ensemble result by </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">over 1 BLEU. On English-to-French translation, we outperform the previoussingle </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.'</span>,              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Attention is All you Need'</span>,                                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2017'</span>,                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'moddate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2018-02-12T21:22:10-08:00'</span>,                                             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'published'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2017'</span>,                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Conference Proceedings'</span>,                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'firstpage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5998'</span>,                                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'book'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Advances in Neural Information Processing Systems 30'</span>,                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Paper accepted and presented at the Neural Information Processing </span>  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">Systems Conference (http://nips.cc/)'</span>,                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'editors'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">and S. Vishwanathan and R. Garnett'</span>,                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin'</span>,                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'lastpage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'6008'</span>,                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../assets/NIPS-2017-attention-is-all-you-need-Paper.pdf'</span>,                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"font-weight: bold\">}</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">model_computed_fields</span> = <span style=\"font-weight: bold\">{}</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>          <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">model_config</span> = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'extra'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ignore'</span><span style=\"font-weight: bold\">}</span>                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>           <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">model_extra</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>          <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">model_fields</span> = <span style=\"font-weight: bold\">{</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FieldInfo</span><span style=\"font-weight: bold\">(</span>                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                 <span style=\"color: #808000; text-decoration-color: #808000\">annotation</span>=<span style=\"color: #800080; text-decoration-color: #800080\">Union</span><span style=\"font-weight: bold\">[</span>str, NoneType<span style=\"font-weight: bold\">]</span>,                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                 <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                 <span style=\"color: #808000; text-decoration-color: #808000\">default</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                 <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_PydanticGeneralMetadata</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">coerce_numbers_to_str</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)]</span>                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"font-weight: bold\">)</span>,                                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FieldInfo</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">annotation</span>=<span style=\"color: #800080; text-decoration-color: #800080\">dict</span>, <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">default_factory</span>=<span style=\"color: #800080; text-decoration-color: #800080\">dict</span><span style=\"font-weight: bold\">)</span>,       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'page_content'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FieldInfo</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">annotation</span>=<span style=\"color: #800080; text-decoration-color: #800080\">str</span>, <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>,                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">FieldInfo</span><span style=\"font-weight: bold\">(</span>                                                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                 <span style=\"color: #808000; text-decoration-color: #808000\">annotation</span>=<span style=\"color: #800080; text-decoration-color: #800080\">Literal</span><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span><span style=\"font-weight: bold\">]</span>,                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                 <span style=\"color: #808000; text-decoration-color: #808000\">required</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                 <span style=\"color: #808000; text-decoration-color: #808000\">default</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                             <span style=\"font-weight: bold\">)</span>                                                                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"font-weight: bold\">}</span>                                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>      <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">model_fields_set</span> = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'page_content'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'metadata'</span><span style=\"font-weight: bold\">}</span>                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>          <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">page_content</span> = <span style=\"color: #008000; text-decoration-color: #008000\">'illia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">based on complex recurrent or\\nconvolutional neural networks that include an encoder </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">and a decoder. The best\\nperforming models also connect the encoder and decoder through</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">an attention\\nmechanism. We propose a new simple network architecture, the </span>             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and </span>     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">convolutions\\nentirely. Experiments on two machine translation tasks show these models </span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                         <span style=\"color: #008000; text-decoration-color: #008000\">to'</span>                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                  <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">type</span> = <span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'langchain_core.documents.base.Document'\u001b[0m\u001b[1;34m>\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mClass for storing a piece of text and associated metadata.\u001b[0m                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m                                                                                                   \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   \u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m                                                                                              \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[32m'producer'\u001b[0m: \u001b[32m'PyPDF2'\u001b[0m,                                                                               \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[32m'creator'\u001b[0m: \u001b[32m'PyPDF'\u001b[0m,                                                                                 \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[32m'creationdate'\u001b[0m: \u001b[32m''\u001b[0m,                                                                                 \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[32m'subject'\u001b[0m: \u001b[32m'Neural Information Processing Systems http://nips.cc/'\u001b[0m,                                 \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[32m'publisher'\u001b[0m: \u001b[32m'Curran Associates, Inc.'\u001b[0m,                                                             \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[32m'language'\u001b[0m: \u001b[32m'en-US'\u001b[0m,                                                                                \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[32m'created'\u001b[0m: \u001b[32m'2017'\u001b[0m,                                                                                  \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[32m'eventtype'\u001b[0m: \u001b[32m'Poster'\u001b[0m,                                                                              \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[32m'description-abstract'\u001b[0m: \u001b[32m'The dominant sequence transduction models are based on compl'\u001b[0m+\u001b[1;36m798\u001b[0m,         \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Attention is All you Need'\u001b[0m,                                                               \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   │   \u001b[0m\u001b[33m...\u001b[0m +\u001b[1;36m14\u001b[0m                                                                                             \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,                                                                                                      \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   \u001b[0m\u001b[33mpage_content\u001b[0m=\u001b[32m'illia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence tr'\u001b[0m+\u001b[1;36m437\u001b[0m                       \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[1m)\u001b[0m                                                                                                           \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                    \u001b[3;33mid\u001b[0m = \u001b[3;35mNone\u001b[0m                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m         \u001b[3;33mlc_attributes\u001b[0m = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m            \u001b[3;33mlc_secrets\u001b[0m = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m              \u001b[3;33mmetadata\u001b[0m = \u001b[1m{\u001b[0m                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'producer'\u001b[0m: \u001b[32m'PyPDF2'\u001b[0m,                                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'creator'\u001b[0m: \u001b[32m'PyPDF'\u001b[0m,                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'creationdate'\u001b[0m: \u001b[32m''\u001b[0m,                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'subject'\u001b[0m: \u001b[32m'Neural Information Processing Systems http://nips.cc/'\u001b[0m,                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'publisher'\u001b[0m: \u001b[32m'Curran Associates, Inc.'\u001b[0m,                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'language'\u001b[0m: \u001b[32m'en-US'\u001b[0m,                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'created'\u001b[0m: \u001b[32m'2017'\u001b[0m,                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'eventtype'\u001b[0m: \u001b[32m'Poster'\u001b[0m,                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'description-abstract'\u001b[0m: \u001b[32m'The dominant sequence transduction models are based on \u001b[0m    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mcomplex recurrent orconvolutional neural networks in an encoder and decoder \u001b[0m            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mconfiguration. The best performing such models also connect the encoder and decoder \u001b[0m    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mthrough an attentionm echanisms.  We propose a novel, simple network architecture based\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32msolely onan attention mechanism, dispensing with recurrence and convolutions \u001b[0m           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mentirely.Experiments on two machine translation tasks show these models to be \u001b[0m          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32msuperiorin quality while being more parallelizable and requiring significantly less \u001b[0m    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mtimeto train. Our single model with 165 million parameters, achieves 27.5 BLEU \u001b[0m         \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32monEnglish-to-German translation, improving over the existing best ensemble result by \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mover 1 BLEU. On English-to-French translation, we outperform the previoussingle \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mstate-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.'\u001b[0m,              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'title'\u001b[0m: \u001b[32m'Attention is All you Need'\u001b[0m,                                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'date'\u001b[0m: \u001b[32m'2017'\u001b[0m,                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'moddate'\u001b[0m: \u001b[32m'2018-02-12T21:22:10-08:00'\u001b[0m,                                             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'published'\u001b[0m: \u001b[32m'2017'\u001b[0m,                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'type'\u001b[0m: \u001b[32m'Conference Proceedings'\u001b[0m,                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'firstpage'\u001b[0m: \u001b[32m'5998'\u001b[0m,                                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'book'\u001b[0m: \u001b[32m'Advances in Neural Information Processing Systems 30'\u001b[0m,                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'description'\u001b[0m: \u001b[32m'Paper accepted and presented at the Neural Information Processing \u001b[0m  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mSystems Conference \u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttp://nips.cc/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'editors'\u001b[0m: \u001b[32m'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mand S. Vishwanathan and R. Garnett'\u001b[0m,                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'author'\u001b[0m: \u001b[32m'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mAidan N. Gomez, Łukasz Kaiser, Illia Polosukhin'\u001b[0m,                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'lastpage'\u001b[0m: \u001b[32m'6008'\u001b[0m,                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'source'\u001b[0m: \u001b[32m'../assets/NIPS-2017-attention-is-all-you-need-Paper.pdf'\u001b[0m,                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'total_pages'\u001b[0m: \u001b[1;36m11\u001b[0m,                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'page'\u001b[0m: \u001b[1;36m0\u001b[0m,                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'page_label'\u001b[0m: \u001b[32m'1'\u001b[0m                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[1m}\u001b[0m                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[3;33mmodel_computed_fields\u001b[0m = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m          \u001b[3;33mmodel_config\u001b[0m = \u001b[1m{\u001b[0m\u001b[32m'extra'\u001b[0m: \u001b[32m'ignore'\u001b[0m\u001b[1m}\u001b[0m                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m           \u001b[3;33mmodel_extra\u001b[0m = \u001b[3;35mNone\u001b[0m                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m          \u001b[3;33mmodel_fields\u001b[0m = \u001b[1m{\u001b[0m                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'id'\u001b[0m: \u001b[1;35mFieldInfo\u001b[0m\u001b[1m(\u001b[0m                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                 \u001b[33mannotation\u001b[0m=\u001b[35mUnion\u001b[0m\u001b[1m[\u001b[0mstr, NoneType\u001b[1m]\u001b[0m,                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                 \u001b[33mrequired\u001b[0m=\u001b[3;91mFalse\u001b[0m,                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                 \u001b[33mdefault\u001b[0m=\u001b[3;35mNone\u001b[0m,                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                 \u001b[33mmetadata\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;35m_PydanticGeneralMetadata\u001b[0m\u001b[1m(\u001b[0m\u001b[33mcoerce_numbers_to_str\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[1m)\u001b[0m,                                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'metadata'\u001b[0m: \u001b[1;35mFieldInfo\u001b[0m\u001b[1m(\u001b[0m\u001b[33mannotation\u001b[0m=\u001b[35mdict\u001b[0m, \u001b[33mrequired\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33mdefault_factory\u001b[0m=\u001b[35mdict\u001b[0m\u001b[1m)\u001b[0m,       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'page_content'\u001b[0m: \u001b[1;35mFieldInfo\u001b[0m\u001b[1m(\u001b[0m\u001b[33mannotation\u001b[0m=\u001b[35mstr\u001b[0m, \u001b[33mrequired\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m,                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[32m'type'\u001b[0m: \u001b[1;35mFieldInfo\u001b[0m\u001b[1m(\u001b[0m                                                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                 \u001b[33mannotation\u001b[0m=\u001b[35mLiteral\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'Document'\u001b[0m\u001b[1m]\u001b[0m,                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                 \u001b[33mrequired\u001b[0m=\u001b[3;91mFalse\u001b[0m,                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                 \u001b[33mdefault\u001b[0m=\u001b[32m'Document'\u001b[0m                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                             \u001b[1m)\u001b[0m                                                                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[1m}\u001b[0m                                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m      \u001b[3;33mmodel_fields_set\u001b[0m = \u001b[1m{\u001b[0m\u001b[32m'page_content'\u001b[0m, \u001b[32m'metadata'\u001b[0m\u001b[1m}\u001b[0m                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m          \u001b[3;33mpage_content\u001b[0m = \u001b[32m'illia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mbased on complex recurrent or\\nconvolutional neural networks that include an encoder \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mand a decoder. The best\\nperforming models also connect the encoder and decoder through\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32man attention\\nmechanism. We propose a new simple network architecture, the \u001b[0m             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mTransformer,\\nbased solely on attention mechanisms, dispensing with recurrence and \u001b[0m     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mconvolutions\\nentirely. Experiments on two machine translation tasks show these models \u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                         \u001b[32mto'\u001b[0m                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                  \u001b[3;33mtype\u001b[0m = \u001b[32m'Document'\u001b[0m                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "\n",
    "docs_chunk = text_splitter.split_documents(documents)\n",
    "\n",
    "pretty_print(f\"[bold white]Length of split documents: {len(docs_chunk)}[/]\")\n",
    "# inspect(docs_chunk[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea7ca3",
   "metadata": {},
   "source": [
    "### **Semantic One**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c069d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     ID              SIZE      MODIFIED       \n",
      "llama3.1:8b              46e0c10c039e    4.9 GB    27 minutes ago    \n",
      "nomic-embed-text:v1.5    0a109f422b47    274 MB    25 hours ago      \n",
      "deepseek-r1:1.5b         e0979632db5a    1.1 GB    7 days ago        \n",
      "llava:13b                0d0eb4d7f485    8.0 GB    2 months ago      \n",
      "mistral:latest           3944fe81ec14    4.1 GB    2 months ago      \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3340ce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Length of semantic chunks: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Length of semantic chunks: \u001b[1;36m31\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'producer'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PyPDF2'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'creator'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PyPDF'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'creationdate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'subject'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Neural Information Processing Systems http://nips.cc/'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'publisher'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Curran Associates, Inc.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en-US'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'created'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2017'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'eventtype'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Poster'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'description-abstract'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Attention is All you Need'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2017'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'moddate'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2018-02-12T21:22:10-08:00'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'published'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2017'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Conference Proceedings'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'firstpage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5998'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'book'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Advances in Neural Information Processing Systems 30'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'editors'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'author'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'lastpage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'6008'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'../assets/NIPS-2017-attention-is-all-you-need-Paper.pdf'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'total_pages'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'page'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'page_label'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser ∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. 1 Introduction\\nRecurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13]. ∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research. †Work performed while at Google Brain.'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'producer'\u001b[0m: \u001b[32m'PyPDF2'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'creator'\u001b[0m: \u001b[32m'PyPDF'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'creationdate'\u001b[0m: \u001b[32m''\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'subject'\u001b[0m: \u001b[32m'Neural Information Processing Systems http://nips.cc/'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'publisher'\u001b[0m: \u001b[32m'Curran Associates, Inc.'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'language'\u001b[0m: \u001b[32m'en-US'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'created'\u001b[0m: \u001b[32m'2017'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'eventtype'\u001b[0m: \u001b[32m'Poster'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'description-abstract'\u001b[0m: \u001b[32m'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Attention is All you Need'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'date'\u001b[0m: \u001b[32m'2017'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'moddate'\u001b[0m: \u001b[32m'2018-02-12T21:22:10-08:00'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'published'\u001b[0m: \u001b[32m'2017'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'Conference Proceedings'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'firstpage'\u001b[0m: \u001b[32m'5998'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'book'\u001b[0m: \u001b[32m'Advances in Neural Information Processing Systems 30'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'description'\u001b[0m: \u001b[32m'Paper accepted and presented at the Neural Information Processing Systems Conference \u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttp://nips.cc/\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'editors'\u001b[0m: \u001b[32m'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'author'\u001b[0m: \u001b[32m'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'lastpage'\u001b[0m: \u001b[32m'6008'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'../assets/NIPS-2017-attention-is-all-you-need-Paper.pdf'\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'total_pages'\u001b[0m: \u001b[1;36m11\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'page'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[32m'page_label'\u001b[0m: \u001b[32m'1'\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mpage_content\u001b[0m=\u001b[32m'Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser ∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. 1 Introduction\\nRecurrent neural networks, long short-term memory \u001b[0m\u001b[32m[\u001b[0m\u001b[32m12\u001b[0m\u001b[32m]\u001b[0m\u001b[32m and gated recurrent \u001b[0m\u001b[32m[\u001b[0m\u001b[32m7\u001b[0m\u001b[32m]\u001b[0m\u001b[32m neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation \u001b[0m\u001b[32m[\u001b[0m\u001b[32m 29, 2, 5\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures \u001b[0m\u001b[32m[\u001b[0m\u001b[32m31, 21, 13\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. ∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research. †Work performed while at Google Brain.'\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text:v1.5\")\n",
    "semantic_splitter = SemanticChunker(embeddings=embedding_model)\n",
    "semantic_chunks = semantic_splitter.split_documents(documents=documents)\n",
    "\n",
    "pretty_print(f\"Length of semantic chunks: {len(semantic_chunks)}\")\n",
    "pprint(semantic_chunks[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bcad70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Transformer is a type of neural network architecture proposed in the paper \"Attention is All You Need\" by Ashish Vaswani et al., published at the Neural Information Processing Systems (NIPS) Conference in 2017. The Transformer model is designed for sequence-to-sequence tasks, such as machine translation, and it significantly outperformed existing models while being more parallelizable and requiring less training time.\n",
      "\n",
      "The Transformer architecture consists of an encoder and a decoder, both built using self-attention mechanisms instead of recurrence or convolutions. Here is a detailed breakdown of the Transformer model:\n",
      "\n",
      "1. Encoder: The encoder is composed of multiple identical layers stacked on top of each other. Each layer in the encoder contains two sub-layers followed by layer normalization and residual connections. The first sub-layer applies self-attention to the input, while the second sub-layer is a fully connected feed-forward network (FCFFN). To facilitate residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmodel = 512.\n",
      "\n",
      "2. Decoder: The decoder also consists of a stack of N = 6 identical layers. It includes an additional third sub-layer that performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections and layer normalization around each of the sub-layers in the decoder. We modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking ensures that the predictions for position i can depend only on the known outputs at positions less than i.\n",
      "\n",
      "3. Attention: An attention function maps a query, keys, and values to an output. The query, keys, values, and output are all vectors. The self-attention mechanism allows the model to focus on different parts of the input sequence when generating each token in the output sequence.\n",
      "\n",
      "The Transformer architecture has become widely popular due to its ability to handle long sequences more effectively than traditional recurrent neural network architectures while being parallelizable and requiring less computational resources for training."
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableParallel\n",
    "\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=semantic_chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"../DB/transformer_paper_db\"\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=\"mistral:latest\")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a helpful assistant. Here is one context {context}\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "])\n",
    "\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(context=vectorstore.as_retriever(search_kwargs={\"k\": 2}),question=RunnablePassthrough()) |\n",
    "    {\"context\": vectorstore.as_retriever(search_kwargs={\"k\": 2}),\"question\":RunnablePassthrough()} | # RunnableParallel\n",
    "    prompt_template | \n",
    "    llm |\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "for chunk in chain.stream(\"Tell me about transformers in details.\"):\n",
    "    print(chunk,end=\"\",flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
