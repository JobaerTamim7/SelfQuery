{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credit : ChatGPT , StackOverflow, bs4 documentation**\n",
    "\n",
    "**How I made this?**\n",
    "\n",
    "Primarily I asked GPT for the answer. Based on that answer I googled my interests. Then again prompt GPT for better response. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing BeautifulSoup\n",
    "```bash\n",
    "    apt-get install python3-bs4    #for installing globally\n",
    "```\n",
    "```bash\n",
    "    poetry add bs4     # poetry installations     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsers for Beautiful Soup\n",
    "\n",
    "1. **`html.parser`**:\n",
    "   - **Built-in Python parser** (no extra installation required).\n",
    "   - **Best for lightweight projects** with simple, well-structured HTML.\n",
    "   - **Pros**: Quick and easy to set up, as it comes with Python.\n",
    "   - **Cons**: Less tolerant of broken or messy HTML compared to other parsers.\n",
    "\n",
    "2. **`lxml`**:\n",
    "   - **Fastest parser** with advanced features like **XPath** and **XSLT** support.\n",
    "   - **Requires installation** of `lxml` library (may need additional dependencies on some systems).\n",
    "   - **Pros**: High speed and memory efficiency; handles large HTML documents well.\n",
    "   - **Cons**: Not as tolerant of malformed HTML as `html5lib`.\n",
    "\n",
    "3. **`html5lib`**:\n",
    "   - **HTML5-compliant parser** that strictly follows HTML5 specifications.\n",
    "   - **Best for messy or broken HTML**; it’s very lenient and similar to how browsers interpret HTML.\n",
    "   - **Pros**: Highly tolerant of errors and imperfections, ensuring well-formed output.\n",
    "   - **Cons**: Slower than `lxml` and requires additional dependencies.\n",
    "\n",
    "### Summary of Parser Choices\n",
    "\n",
    "| Parser        | Pros                                        | Cons                              | Best For                      |\n",
    "|---------------|---------------------------------------------|-----------------------------------|-------------------------------|\n",
    "| `html.parser` | No dependencies, good for simple HTML       | Less error-tolerant               | Lightweight projects          |\n",
    "| `lxml`        | Fast, advanced features (XPath, XSLT)       | Requires installation             | Large, well-formed HTML       |\n",
    "| `html5lib`    | Highly tolerant, follows HTML5 spec         | Slower, requires dependencies     | Messy or broken HTML          |\n",
    "\n",
    "\n",
    "For more Parser : [parser](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.html#differences-between-parsers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import  Tag\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from rich.pretty import pprint\n",
    "# import json //I do not need json here\n",
    "import os\n",
    "\n",
    "\n",
    "url = 'https://myanimelist.net/topanime.php'\n",
    "response : requests.Response = requests.get(url)\n",
    "anime_soup : BeautifulSoup = BeautifulSoup(response.text, 'lxml') # here anime_soup object is a tree of tags \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objects in BeautifulSoup**\n",
    "- Tag\n",
    "- BeautifulSoup\n",
    "- Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BeautifulSoup Object**\n",
    "\n",
    "A BeautifulSoup object is created when you feed it's constructor an HTML or XML document. This object represents the entire structure of the web page or document you’re working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a directory and writing the HTML to a file\n",
    "try:\n",
    "    os.mkdir('templates')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "except Exception as e:\n",
    "    print(f\"Error creating directory: {e}\")\n",
    "finally:\n",
    "    try:\n",
    "        with open('templates/top_anime.html', 'w') as file:\n",
    "            file.write(anime_soup.prettify())\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to file: {e}\")\n",
    "\n",
    "# Reading the HTML file and making soup\n",
    "try:\n",
    "    soup : BeautifulSoup = BeautifulSoup(open(\"templates/top_anime.html\"), 'lxml')\n",
    "except Exception as e:\n",
    "    print(f\"Error reading the HTML file: {e}\")\n",
    "\n",
    "# Parsing the HTML\n",
    "try:\n",
    "    table : Tag = soup.find('table', class_='top-ranking-table')\n",
    "    rank_animes : List[Tag] = table.find_all('tr', class_='ranking-list')\n",
    "    rank_animes_dict : List[Dict[str,str]] = []\n",
    "\n",
    "    for anime in rank_animes:\n",
    "        rank_tag : Tag = anime.find('td', class_='rank ac')\n",
    "        title_tag : Tag = anime.find('td', class_='title')\n",
    "\n",
    "        rank : str|None = rank_tag.text.strip() if rank_tag else None\n",
    "        title : str|None = title_tag.find('h3', class_='anime_ranking_h3').text.strip() if title_tag else None\n",
    "        ep : str|None = title_tag.find('div', class_='information di-ib mt4').contents[0].text.strip() if title_tag else None\n",
    "        ep : str|None = re.sub(r'\\D', '', ep) if ep else None\n",
    "\n",
    "        rank_animes_dict.append(\n",
    "            {\n",
    "                'Rank': rank,\n",
    "                'Title': title,\n",
    "                'Episodes': ep\n",
    "            }\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing the HTML: {e}\")\n",
    "\n",
    "print(rank_animes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.DataFrame(rank_animes_dict)\n",
    "except Exception as e:  \n",
    "    print(f\"Error creating DataFrame: {e}\")\n",
    "finally:\n",
    "    try:\n",
    "        os.mkdir('data')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f'Error creating directory: {e}')\n",
    "    finally:\n",
    "        try:\n",
    "            df.to_json('data/top_anime.json', orient='records', indent=4)\n",
    "            df.to_excel('data/top_anime.xlsx', index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing to file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrapper-pwK1knV8-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
